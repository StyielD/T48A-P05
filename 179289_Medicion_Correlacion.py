# -*- coding: utf-8 -*-
"""Copia de Escalas de medición y correlación.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1auc3GVSO9FoRl-4btXKT54cCMDhauHDH

# Escalas de Medición y Correlación en Python

## Escalas de Medición

Las escalas de medición son categorías que describen la naturaleza de la información dentro de los valores asignados a las variables. Estas escalas son esenciales para determinar qué tipo de análisis estadístico es apropiado para los datos. Hay cuatro escalas principales: nominal, ordinal, de intervalo y de razón.

### 1. Escala Nominal
- **Definición**: Clasifica los datos en categorías distintas que no tienen un orden intrínseco.
- **Ejemplos**: Género (masculino, femenino), color de ojos (azul, verde, marrón).
- **Operaciones Permitidas**: Contar frecuencias, modo.
- **Análisis Estadístico**: Pruebas de chi-cuadrado, tablas de contingencia.

### 2. Escala Ordinal
- **Definición**: Clasifica los datos en categorías que tienen un orden específico, pero las diferencias entre las categorías no son necesariamente iguales.
- **Ejemplos**: Niveles de satisfacción (muy insatisfecho, insatisfecho, neutral, satisfecho, muy satisfecho), rangos militares.
- **Operaciones Permitidas**: Contar frecuencias, mediana, percentiles.
- **Análisis Estadístico**: Pruebas de rango de Wilcoxon, correlación de Spearman.

### 3. Escala de Intervalo
- **Definición**: Clasifica los datos en categorías con un orden específico y con intervalos iguales entre las categorías, pero no tiene un verdadero cero.
- **Ejemplos**: Temperatura en grados Celsius o Fahrenheit, años en un calendario.
- **Operaciones Permitidas**: Suma, resta, media, desviación estándar.
- **Análisis Estadístico**: Análisis de varianza (ANOVA), correlación de Pearson.

### 4. Escala de Razón
- **Definición**: Similar a la escala de intervalo, pero con un verdadero cero que indica la ausencia de la cantidad medida.
- **Ejemplos**: Peso, altura, ingresos.
- **Operaciones Permitidas**: Todas las operaciones matemáticas (suma, resta, multiplicación, división).
- **Análisis Estadístico**: Regresión lineal, análisis de varianza (ANOVA), correlación de Pearson.

## Importancia de las Escalas de Medición
Entender las escalas de medición es crucial porque determina el tipo de análisis estadístico que se puede realizar. Por ejemplo, no tendría sentido calcular una media para datos nominales, ya que no hay un orden o intervalo entre las categorías.

## Ejemplo Práctico
Supongamos que tienes un conjunto de datos sobre la satisfacción de los clientes con un producto, donde las respuestas son: "muy insatisfecho", "insatisfecho", "neutral", "satisfecho", "muy satisfecho". Esta es una escala ordinal. Puedes calcular la mediana para encontrar el nivel de satisfacción central, pero no sería apropiado calcular una media.

## Implementación en Python
"""

# Importar las bibliotecas necesarias
import pandas as pd

# Datos de ejemplo
data = {
    'Genero': ['Masculino', 'Femenino', 'Femenino', 'Masculino'],
    'Satisfaccion': ['Muy satisfecho', 'Satisfecho', 'Neutral', 'Insatisfecho'],
    'Edad': [23, 45, 31, 35],
    'Ingresos': [50000, 60000, 55000, 52000]
}

# Crear un DataFrame
df = pd.DataFrame(data)

# Convertir la columna 'Satisfaccion' a una categoría ordinal
satisfaccion_categoria = pd.Categorical(df['Satisfaccion'], categories=['Muy insatisfecho', 'Insatisfecho', 'Neutral', 'Satisfecho', 'Muy satisfecho'], ordered=True)
df['Satisfaccion'] = satisfaccion_categoria

# Mostrar el DataFrame
print(df)

"""# Teoría de la Correlación y Ejemplo con NumPy

## Teoría de la Correlación

### ¿Qué es la Correlación?
La correlación es una medida estadística que indica la fuerza y la dirección de una relación lineal entre dos variables. Se representa comúnmente por el coeficiente de correlación de Pearson, que varía entre -1 y 1.

- **Coeficiente de Correlación de Pearson (r)**:
  - **r = 1**: Correlación positiva perfecta.
  - **r = -1**: Correlación negativa perfecta.
  - **r = 0**: No hay correlación lineal.

### Tipos de Correlación
1. **Correlación Positiva**: A medida que una variable aumenta, la otra también lo hace.
2. **Correlación Negativa**: A medida que una variable aumenta, la otra disminuye.
3. **Sin Correlación**: No hay una relación lineal aparente entre las variables.

### Importancia de la Correlación
La correlación es útil en diversas áreas como la economía, la biología, la psicología y la ingeniería, ya que ayuda a identificar y cuantificar relaciones entre variables. Sin embargo, es importante recordar que la correlación no implica causalidad; es decir, una correlación entre dos variables no significa que una cause la otra.

## Ejemplo Práctico con NumPy

Vamos a calcular la correlación entre dos conjuntos de datos utilizando NumPy.


"""

import numpy as np

# Datos de ejemplo
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

# Calcular la matriz de correlación
correlation_matrix = np.corrcoef(x, y)

# Extraer el coeficiente de correlación
correlation_coefficient = correlation_matrix[0, 1]

print("Matriz de correlación:")
print(correlation_matrix)

print("\nCoeficiente de correlación de Pearson:")
print(correlation_coefficient)

"""# Teoría de la Correlación y Ejemplo con NumPy

## Teoría de la Correlación

### ¿Qué es la Correlación?
La correlación es una medida estadística que indica la fuerza y la dirección de una relación lineal entre dos variables. Se representa comúnmente por el coeficiente de correlación de Pearson, que varía entre -1 y 1.

- **Coeficiente de Correlación de Pearson (r)**:
  - **r = 1**: Correlación positiva perfecta.
  - **r = -1**: Correlación negativa perfecta.
  - **r = 0**: No hay correlación lineal.

### Tipos de Correlación
1. **Correlación Positiva**: A medida que una variable aumenta, la otra también lo hace.
2. **Correlación Negativa**: A medida que una variable aumenta, la otra disminuye.
3. **Sin Correlación**: No hay una relación lineal aparente entre las variables.

### Importancia de la Correlación
La correlación es útil en diversas áreas como la economía, la biología, la psicología y la ingeniería, ya que ayuda a identificar y cuantificar relaciones entre variables. Sin embargo, es importante recordar que la correlación no implica causalidad; es decir, una correlación entre dos variables no significa que una cause la otra.

### Fórmulas para Calcular la Correlación de Pearson

El coeficiente de correlación de Pearson (\( r \)) mide la fuerza y la dirección de la relación lineal entre dos variables. Aquí están los pasos para calcularlo:

1. **Calcular la Media de cada Variable**:
   - Para la variable $( X ): [ \bar{X} = \frac{1}{n} \sum_{i=1}^{n} X_i ]$
   - Para la variable $( Y ): [ \bar{Y} = \frac{1}{n} \sum_{i=1}^{n} Y_i ]$

2. **Calcular las Desviaciones de cada Valor respecto a su Media**:
   - Para $( X ): [ X_i - \bar{X} ]$
   - Para $( Y ): [ Y_i - \bar{Y} ]$

3. **Calcular el Producto de las Desviaciones para cada Par de Valores**:
   $[ (X_i - \bar{X})(Y_i - \bar{Y}) ]$

4. **Sumar los Productos de las Desviaciones**:
   $[ \sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y}) ]$

5. **Calcular la Desviación Estándar de cada Variable**:
   - Para $( X ): [ s_X = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (X_i - \bar{X})^2} ]$
   - Para $( Y ): [ s_Y = \sqrt{\frac{1}{n-1} \sum_{i=1}^{n} (Y_i - \bar{Y})^2} ]$

6. **Calcular el Coeficiente de Correlación de Pearson**:
   $[ r = \frac{\sum_{i=1}^{n} (X_i - \bar{X})(Y_i - \bar{Y})}{(n-1) s_X s_Y} ]$

## Ejemplo Práctico con NumPy

Vamos a calcular la correlación entre dos conjuntos de datos utilizando NumPy.
"""

import numpy as np

# Datos de ejemplo
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

# Calcular la media
mean_x = np.mean(x)
mean_y = np.mean(y)

# Calcular las desviaciones
deviation_x = x - mean_x
deviation_y = y - mean_y

# Calcular el producto de las desviaciones
product_deviations = deviation_x * deviation_y

# Sumar los productos de las desviaciones
sum_product_deviations = np.sum(product_deviations)

# Calcular la desviación estándar
std_x = np.std(x, ddof=1)
std_y = np.std(y, ddof=1)

# Calcular el coeficiente de correlación de Pearson
r = sum_product_deviations / ((len(x) - 1) * std_x * std_y)

print("Coeficiente de correlación de Pearson:", r)

import numpy as np
# Mínimos cuadrados
x = np.array([1, 2, 3, 4, 5])
y = np.array([2, 4, 6, 8, 10])

# Calcular la media de x e y
x_mean = np.mean(x)
y_mean = np.mean(y)

# Calcular la pendiente (m)
numerator = np.sum((x - x_mean) * (y - y_mean))
denominator = np.sum((x - x_mean)**2)
m = numerator / denominator

# Calcular la ordenada al origen (b)
b = y_mean - m * x_mean

print(f"Pendiente (m): {m}")
print(f"Ordenada al origen (b): {b}")

"""Ejercicio: utiliza los siguientes datos para generar la regresión lineal de cada modelo y la salida ordenala en una tupla con el sigueinte orden (pendiente, ordenada_al_origen, coef_de_correlacion_de_pearson)

| Año | Modelo        | Precio (EUR) |
|-----|---------------|--------------|
| 2020 | Model 3      | 39,990       |
| 2021 | Model 3      | 41,990       |
| 2022 | Model 3      | 43,990       |
| 2023 | Model 3      | 45,990       |
| 2024 | Model 3      | 47,990       |
| 2020 | Model S      | 89,990       |
| 2021 | Model S      | 91,990       |
| 2022 | Model S      | 93,990       |
| 2023 | Model S      | 95,990       |
| 2024 | Model S      | 97,990       |
| 2020 | Model X      | 99,990       |
| 2021 | Model X      | 101,990      |
| 2022 | Model X      | 103,990      |
| 2023 | Model X      | 105,990      |
| 2024 | Model X      | 107,990      |
| 2020 | Model Y      | 44,990       |
| 2021 | Model Y      | 46,990       |
| 2022 | Model Y      | 48,990       |
| 2023 | Model Y      | 50,990       |
| 2024 | Model Y      | 52,990       |
"""

#Funciones
def regresion_lineal_model_3():
  x = np.array([2020, 2021, 2022, 2023, 2024])
  y = np.array([39990, 41990, 43990, 45990, 47990])
  x_mean = np.mean(x)
  y_mean = np.mean(y)
  desviacion_x = x - x_mean
  desviacion_y = y - y_mean
  # Calcular la pendiente (m)
  numerator = np.sum((x - x_mean) * (y - y_mean))
  denominator = np.sum((x - x_mean)**2)
  m = numerator / denominator #Pendiente
  # Calcular la ordenada al origen (b)
  b = y_mean - m * x_mean
  producto_desviaciones = desviacion_x * desviacion_y
  sum_producto_desviaciones = np.sum(producto_desviaciones)
  std_i = np.std(x, ddof=1)
  std_p = np.std(y, ddof=1)
  r = sum_producto_desviaciones / ((len(x) - 1) * std_i * std_p)
  return (m, b, r)

def regresion_lineal_model_s():
  x= np.array([2020, 2021, 2022, 2023, 2024])
  y = np.array([89990, 91990, 93990, 95990, 97990])
  x_mean = np.mean(x)
  y_mean = np.mean(y)
  desviacion_x = x - x_mean
  desviacion_y = y - y_mean
  # Calcular la pendiente (m)
  numerator = np.sum((x - x_mean) * (y - y_mean))
  denominator = np.sum((x - x_mean)**2)
  m = numerator / denominator #Pendiente
  # Calcular la ordenada al origen (b)
  b = y_mean - m * x_mean
  producto_desviaciones = desviacion_x * desviacion_y
  sum_producto_desviaciones = np.sum(producto_desviaciones)
  std_i = np.std(x, ddof=1)
  std_p = np.std(y, ddof=1)
  r = sum_producto_desviaciones / ((len(x) - 1) * std_i * std_p)
  return (m, b, r)

def regresion_lineal_model_x():
  x = np.array([2020, 2021, 2022, 2023, 2024])
  y = np.array([99990,101990,103990, 105990, 107990])
  x_mean = np.mean(x)
  y_mean = np.mean(y)
  desviacion_x = x - x_mean
  desviacion_y = y - y_mean
  # Calcular la pendiente (m)
  numerator = np.sum((x - x_mean) * (y - y_mean))
  denominator = np.sum((x - x_mean)**2)
  m = numerator / denominator #Pendiente
  # Calcular la ordenada al origen (b)
  b = y_mean - m * x_mean
  producto_desviaciones = desviacion_x * desviacion_y
  sum_producto_desviaciones = np.sum(producto_desviaciones)
  std_i = np.std(x, ddof=1)
  std_p = np.std(y, ddof=1)
  r = sum_producto_desviaciones / ((len(x) - 1) * std_i * std_p)
  return (m, b, r)

def regresion_lineal_model_y():
  x = np.array([2020, 2021, 2022, 2023, 2024])
  y = np.array([44990, 46990, 48990, 50990, 52990])
  x_mean = np.mean(x)
  y_mean = np.mean(y)
  desviacion_x = x - x_mean
  desviacion_y = y - y_mean
  # Calcular la pendiente (m)
  numerator = np.sum((x - x_mean) * (y - y_mean))
  denominator = np.sum((x - x_mean)**2)
  m = numerator / denominator #Pendiente
  # Calcular la ordenada al origen (b)
  b = y_mean - m * x_mean
  producto_desviaciones = desviacion_x * desviacion_y
  sum_producto_desviaciones = np.sum(producto_desviaciones)
  std_i = np.std(x, ddof=1)
  std_p = np.std(y, ddof=1)
  r = sum_producto_desviaciones / ((len(x) - 1) * std_i * std_p)
  return (m, b, r)
